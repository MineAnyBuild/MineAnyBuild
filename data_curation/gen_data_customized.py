import json
import os
from PIL import Image, ImageDraw, ImageFont
import random
import requests

# --- 配置常量 ---
API_URL = 'https://xxxxx/v1/chat/completions' # fill in your api url here
API_KEY = 'sk-xxxxx' # fill in your api key here
MODEL_NAME = 'gpt-4.1' # specify your llm model. we use gpt-4.1 here.


#############################################################
# Data Curation for Architectures and Planning tasks
#############################################################

def address_architectures_data(arch_name, original_input):
    '''
    Data curation function for architectures data.
    '''
    # the input path is obtained by the previous step.
    input_root = './benchmark_data/original_wiki_rawdata'
    output_root = './benchmark_data/original_wiki_addressed'
    data_source_name = 'Customized'
    # you can modify the above i/o paths and data source name.

    if not os.path.exists(output_root):
        os.makedirs(output_root)
    with open(os.path.join(input_root, f"{arch_name}.json"), 'r') as f1:
        data = json.load(f1)
    if not data:
        return
    out = {}

    start_pos = original_input[arch_name]["start_pos"]
    end_pos = original_input[arch_name]["end_pos"]

    out["data_source"] = data_source_name
    out["name"] = arch_name
    block_amount = 0
    object_materials = []
    ob_cnt = 1
    object_materials_hash = {"air": -1}

    width = end_pos[0]-start_pos[0]+1
    height = end_pos[1]-start_pos[1]+1
    depth = end_pos[2]-start_pos[2]+1
    out["3d_info"] = {"width": width, "height": height, "depth": depth}
    out_blueprint = [[[] for d in range(depth)] for h in range(height)]

    for k, v in data.items():
        w, h, d = int(k.split('_')[0])-start_pos[0], int(k.split('_')[1])-start_pos[1], int(k.split('_')[2])-start_pos[2]
        if v["displayName"] == "Jigsaw Block":
            final_state = v["entity"]["value"]["final_state"]["value"]
            if final_state == "minecraft:structure_void":
                out_blueprint[h][d].append(-1)
            else:
                if final_state.split('minecraft:')[1] not in object_materials:
                    object_materials.append(final_state.split('minecraft:')[1])
                    object_materials_hash[final_state.split('minecraft:')[1]] = ob_cnt
                    ob_cnt += 1
                out_blueprint[h][d].append(object_materials_hash[final_state.split('minecraft:')[1]])
                block_amount += 1
        else:
            if v["name"] != "air":
                block_amount += 1
                obj_name = v["name"]
                if v["_properties"]:
                    temp_str = ""
                    for k1, v1 in v["_properties"].items():
                        temp_str += f"{k1}={v1},".replace("False", "false").replace("True", "true")
                    obj_name = f"{obj_name}[{temp_str[:-1]}]"
                if obj_name not in object_materials:
                    object_materials.append(obj_name)
                    object_materials_hash[obj_name] = ob_cnt
                    ob_cnt += 1
            
                out_blueprint[h][d].append(object_materials_hash[obj_name])
            else:
                out_blueprint[h][d].append(-1)
    out["object_materials"] = object_materials
    out["block_materials"] = object_materials_hash
    out["block_amount"] = block_amount
    out["blueprint"] = out_blueprint
    
    with open(os.path.join(output_root, f'{arch_name}.json'), 'w') as f2:
        json.dump(out, f2, indent=4)


def generate_instructions_cr():
    '''
    Generate instructions for Creativity task
    '''

    input_root = './data/benchmark_data/final_addressed_data/raw'
    output_root = './data/benchmark_data/final_addressed_data/addressed'
    # you can modify the above i/o paths based on your demands.

    simple_verbs = ["Build", "Construct", "Erect", "Establish", "Raise", "Set up", "Assemble", "Develop", "Fabricate", "Put up", "Create", "Form", "Design"]  # you can expand this list

    archs = os.listdir(input_root)
    for arch in archs:
        # print(arch)
        arch_json_path = os.path.join(input_root, arch)
        with open(arch_json_path, 'r') as f1:
            arch_data = json.load(f1)
        
        arch_name = arch_data["name"] # it depends on your data 
        # you can annotate a description manually or generated by LLMs, and use it to generate instructions.

        with open(os.path.join(output_root, arch), 'r') as f2:
            output_data = json.load(f2)
        if "instructions" not in output_data:
            output_data["instructions"] = {
            "simple": [],
            "instr_follow": "",
            "spatial_plan": ""
        }
        output_data["instructions"]["simple"] = [f"{verb} a {arch_name}." for verb in random.sample(simple_verbs, 3)]
        with open(os.path.join(output_root, arch), 'w') as f2:
            json.dump(output_data, f2, indent=4)




def generate_commands(blueprint, block_materials):
    '''
    Generate commands for building the structure layer by layer. 
    '''

    # Create a reverse mapping from ids to block names.
    id_to_name = {v: k for k, v in block_materials.items()}
    
    result = []
    
    for layer_index, layer in enumerate(blueprint, start=1):
        layer_dict = {}
        for z in range(len(blueprint[0])):
            for x in range(len(blueprint[0][0])):
                block_id = layer[z][x]
                if block_id == -1: # Filter out air blocks
                    continue
                # Get block name and record coordinates
                block_name = id_to_name[block_id]
                if block_name not in layer_dict:
                    layer_dict[block_name] = []
                layer_dict[block_name].append((x, z)) 
                
        commands = []
        for name in sorted(layer_dict.keys()):  # x->z
            sorted_coords = sorted(layer_dict[name], key=lambda c: (c[0], c[1]))
            coords_str = ', '.join(f'({x},{z})' for x, z in sorted_coords)
            commands.append(f'{name}: [{coords_str}]')
        
        result.append(f'Layer {layer_index}: ' + ', '.join(commands))
    
    return '\n'.join(result)


def generate_instructions_su():
    '''
    Generate instructions in the format of Spatial Understanding task.
    '''

    input_root = './data/benchmark_data/final_addressed_data/raw'
    output_root = './data/benchmark_data/final_addressed_data/addressed'
    # you can modify the above i/o paths based on your demands.

    archs = os.listdir(input_root)
    for arch in archs:
        # print(arch)
        arch_json_path = os.path.join(input_root, arch)
        with open(arch_json_path, 'r') as f1:
            arch_data = json.load(f1)
        
        blueprint = arch_data["blueprint"]
        block_materials = arch_data["block_materials"]
        arch_name = arch_data["name"]
        height = arch_data["3d_info"]["height"]
        width = arch_data["3d_info"]["width"]
        depth = arch_data["3d_info"]["depth"]
        commands = generate_commands(blueprint, block_materials)
        template = f"Let's build a {arch_name} structure. This structure has total {height} layers with width {width} and length {depth}.\n{commands}"
        # print(template)
        with open(os.path.join(output_root, arch), 'r') as f2:
            output_data = json.load(f2)
        if "instructions" not in output_data:
            output_data["instructions"] = {
            "simple": [],
            "instr_follow": "",
            "spatial_plan": ""
        }
        output_data["instructions"]["instr_follow"] = template
        with open(os.path.join(output_root, arch), 'w') as f2:
            json.dump(output_data, f2, indent=4)



def get_llm_response(json_content_str, PROMPT_TEMPLATE):
    """
    Query the LLM api to get the instructions for planning tasks.
    """
    headers = {
        'Authorization': f'Bearer {API_KEY}',
        'Content-Type': 'application/json'
    }
    
    full_prompt = f"{PROMPT_TEMPLATE}\n\nInput JSON Data:\n{json_content_str}"

    payload = {
        "model": MODEL_NAME,
        "messages": [
            {"role": "system", "content": "You are an expert in describing Minecraft structure constructions based on JSON data. Follow user instructions precisely. Generate content related solely to construction, excluding any irrelevant content related to user interaction. Describe how to build this object in under 150 words. The output must exclude any coordinates and adhere to natural language norms without structured bullet points or numbered lists."},
            {"role": "user", "content": full_prompt}
        ],
        "temperature": 0.4, # you can specify this
        # "max_tokens": 200 # you can uncomment it depending on your needs
    }

    try:
        response = requests.post(API_URL, headers=headers, json=payload, timeout=120) # you can edit the timeout
        response.raise_for_status()  
        
        api_response = response.json()
        generated_text = api_response['choices'][0].get('message', {}).get('content', '').strip()
        return generated_text
        
    except Exception as e:
        print(f"error: {e}")
        return None



def generate_instructions_sp():
    '''
    Generate instructions for Executable Spatial Plan Generation task
    '''

    input_root = './data/benchmark_data/final_addressed_data/raw'
    output_root = './data/benchmark_data/final_addressed_data/addressed'
    # you can modify the above i/o paths based on your demands.

    PROMPT_TEMPLATE = """Ensure that generated content is related solely to construction, excluding any irrelevant content related to user interaction. Describe how to build this object in under 150 words. Based on the input JSON file, generate a textual description of the structure within the file. The output must exclude any coordinates and adhere to natural language norms without structured bullet points or numbered lists. Examples in the required format: Let's build a Ancient Pillar Ruin structure from bottom to top.\nFirst, place 5 stone_bricks as the shape of a cross twice to build a two-layer foundation.\nThen, place 1 stone_bricks in the center, and place each stone_brick_slab on the last 4 stone_bricks.\nPlace 2 cobblestone_wall vertically reaching a height of two blocks, and then 2 chiseled_stone_bricks similarly on top of the cobblestone_wall.\nLeaning against the top chiseled_stone_bricks, place 4 stone_brick_stairs upside down towards different orientation.\nFinally, place 1 stone_bricks in the center, and place each stone_brick_slab on the 4 stone_brick_stairs."""


    archs = os.listdir(input_root)
    for arch in archs:
        # print(arch)
        arch_json_path = os.path.join(input_root, arch)
        with open(arch_json_path, 'r') as f1:
            arch_data = json.load(f1)

        with open(os.path.join(output_root, arch), 'r') as f2:
            output_data = json.load(f2)
        if "instructions" not in output_data:
            output_data["instructions"] = {
            "simple": [],
            "instr_follow": "",
            "spatial_plan": ""
        }
            
        json_content_str = json.dumps(arch_data, indent=2)
        # json_content_str = generate_commands(arch_data["blueprint"], arch_data["block_materials"])
        # you can input the full json file or only the commands to the LLMs.

        output_data["instructions"]["spatial_plan"] = get_llm_response(json_content_str, PROMPT_TEMPLATE)
        with open(os.path.join(output_root, arch), 'w') as f2:
            json.dump(output_data, f2, indent=4)


#############################################################
# Data Curation for Spatial Reasoning task (VQA)
#############################################################


def address_mental_rotation_data(arch_name, original_input):
    '''
    codes for preprocessing the mental rotation data
    '''

    input_root = './benchmark_data/original_mental_rotation_rawdata'
    output_root = './benchmark_data/original_mental_rotation_addressed'
    if not os.path.exists(output_root):
        os.makedirs(output_root)
    json_path = os.path.join(input_root, f"{arch_name}.json")
    with open(json_path, 'r') as f1:
        data = json.load(f1)
    if not data:
        return
    out = {}

    start_pos = original_input[arch_name]["start_pos"]
    end_pos = original_input[arch_name]["end_pos"]

    out["data_source"] = "Mental Rotation"
    out["name"] = arch_name
    block_amount = 0
    object_materials = []
    ob_cnt = 1
    object_materials_hash = {"air": -1}

    width = end_pos[0]-start_pos[0]+1
    height = end_pos[1]-start_pos[1]+1
    depth = end_pos[2]-start_pos[2]+1
    out["3d_info"] = {"width": width, "height": height, "depth": depth}
    out_blueprint = [[[] for d in range(depth)] for h in range(height)]

    for k, v in data.items():
        w, h, d = int(k.split('_')[0])-start_pos[0], int(k.split('_')[1])-start_pos[1], int(k.split('_')[2])-start_pos[2]
        if v["displayName"] == "Jigsaw Block":
            final_state = v["entity"]["value"]["final_state"]["value"]
            if final_state == "minecraft:structure_void":
                out_blueprint[h][d].append(-1)
            else:
                if final_state.split('minecraft:')[1] not in object_materials:
                    object_materials.append(final_state.split('minecraft:')[1])
                    object_materials_hash[final_state.split('minecraft:')[1]] = ob_cnt
                    ob_cnt += 1
                out_blueprint[h][d].append(object_materials_hash[final_state.split('minecraft:')[1]])
                block_amount += 1
        else:
            if v["name"] != "air":
                block_amount += 1
                if v["name"] not in object_materials:
                    object_materials.append(v["name"])
                    object_materials_hash[v["name"]] = ob_cnt
                    ob_cnt += 1
            out_blueprint[h][d].append(object_materials_hash[v["name"]])
    out["object_materials"] = object_materials
    out["block_materials"] = object_materials_hash
    out["block_amount"] = block_amount
    out["blueprint"] = out_blueprint
    

    with open(os.path.join(output_root, f'{arch_name}.json'), 'w') as f2:
        json.dump(out, f2, indent=4)



def concat_image(output_root, output_name, base_img_path, option_img_paths, gap=5, font_size=40):
    '''
    codes for concatenating images for Spatial Reasoning tasks, with multiple choices from A,B,C,D.
    '''

    base_img = Image.open(base_img_path)
    option_imgs = [Image.open(path) for path in option_img_paths]
    
    opt_width, opt_height = option_imgs[0].size
    base_img = base_img.resize((opt_width, opt_height)) 
    
    middle_gap = gap * 2  
    caption_height = 30  
    
    total_width = opt_width + middle_gap + (opt_width * 2 + gap)
    total_height = max(
        (opt_height * 2 + gap * 1),  
        (opt_height + caption_height)  
    )
 
    canvas = Image.new('RGB', (total_width, total_height), (255, 255, 255))
    draw = ImageDraw.Draw(canvas)
    
    base_y = (total_height - opt_height - caption_height) // 2
    canvas.paste(base_img, (0, base_y))
    
    try:
        font = ImageFont.truetype("arial.ttf", font_size)
    except:
        font = ImageFont.load_default()
    # text_width, text_height = draw.textsize("Original Image", font=font)
    text_bbox = draw.textbbox((0, 0), "Original Image", font=font)
    text_width = text_bbox[2] - text_bbox[0]  # right - left
    text_height = text_bbox[3] - text_bbox[1] # bottom - top
    text_x = (opt_width - text_width) // 2  
    text_y = base_y + opt_height + 5  
    draw.text((text_x, text_y), "Original Image", fill=(0,0,0), font=font)
    
    option_start_x = opt_width + middle_gap
    positions = [
        (option_start_x, 0),
        (option_start_x + opt_width + gap, 0),
        (option_start_x, opt_height + gap),
        (option_start_x + opt_width + gap, opt_height + gap)
    ]
    
    for idx, (img, pos) in enumerate(zip(option_imgs, positions)):
        img = img.resize((opt_width, opt_height))
        canvas.paste(img, pos)

        label = chr(65 + idx)  # A,B,C,D
        draw.text((pos[0]+10, pos[1]+10), label, 
                 fill=(0,0,0), font=font,
                 stroke_width=1, stroke_fill=(255,255,255))
    
    output_path = f"{output_root}/{output_name}.jpg"
    canvas.save(output_path, quality=95)
    print(f"{output_path}")
    return f"{output_name}.jpg"


def concat_single_image(output_root, output_name, base_img_path, input_img_path, gap=10):
    '''
    codes for concatenating images for Spatial Reasoning tasks, for True/False VQAs.
    '''

    base_img = Image.open(base_img_path)
    input_img = Image.open(input_img_path)
    
    base_width, base_height = base_img.size
    input_img = input_img.resize((base_width, base_height))
    
    total_width = base_width + gap + base_width
    total_height = base_height
    
    canvas = Image.new('RGB', (total_width, total_height), (255, 255, 255))
    
    canvas.paste(base_img, (0, 0))
    canvas.paste(input_img, (base_width + gap, 0))
    
    output_path = f"{output_root}/{output_name}.jpg"
    canvas.save(output_path)
    print(f"{output_path}")
    return f"{output_name}.jpg"


def generate_mental_rotation_task_1():
    '''
    codes for generating VQA data for Spatial Reasoning task (question type 1)
    question: Which option is the same as the original image, aside from its orientation?
    '''

    input_root = "./stimuli"
    output_root = "./stimuli_vqa"
    task_cnt = 1
    qa_out = []

    same_group = [["N_1", "RX_0", "RY_2", "RZ_3"],["N_1", "RX_0", "RY_3", "RZ_2"],["N_1", "RX_2", "RY_0", "RZ_3"],["N_1", "RX_2", "RY_3", "RZ_0"],["N_1", "RX_3", "RY_0", "RZ_2"],["N_1", "RX_3", "RY_2", "RZ_0"],["N_2", "RX_0", "RY_1", "RZ_3"],["N_2", "RX_0", "RY_3", "RZ_1"],["N_2", "RX_1", "RY_0", "RZ_3"],["N_2", "RX_1", "RY_3", "RZ_0"],["N_2", "RX_3", "RY_0", "RZ_1"],["N_2", "RX_3", "RY_1", "RZ_0"],["N_3", "RX_0", "RY_1", "RZ_2"],["N_3", "RX_0", "RY_2", "RZ_1"],["N_3", "RX_1", "RY_0", "RZ_2"],["N_3", "RX_1", "RY_2", "RZ_0"],["N_3", "RX_2", "RY_0", "RZ_1"],["N_3", "RX_2", "RY_1", "RZ_0"]]

    for num in range(48):
        random.seed(num+1000)
        mr_dir = f"{input_root}/MR{num+1}"
        for sg in range(len(same_group)):
            out = {}
            out["id"] = f"TSK_SR_1_{task_cnt:04d}"
            out["instruction"] = "Which option is the same as the original image, aside from its orientation?"
            shuffled = random.sample(same_group[sg], len(same_group[sg])) 
            out["metadata"] = f'MR{num+1}_'+''.join([item.replace("_", "") for item in shuffled])
            out["original"] = "N_0.png"
            out["answer"] = chr(65+shuffled.index(same_group[sg][0]))
            pre_concat_images = [f"{mr_dir}/{item}.png" for item in shuffled]
            out["options_image"] = concat_image(output_root, out["id"], f"{mr_dir}/N_0.png", pre_concat_images)
            out["options"] = [f"{item}.png" for item in shuffled]
            qa_out.append(out)
            task_cnt += 1

    with open(f"{output_root}/SpaRea_VQAs_1.json", 'w') as f1:
        json.dump(qa_out, f1, indent=4)


def generate_mental_rotation_task_2():
    '''
    codes for generating VQA data for Spatial Reasoning task (question type 2)
    question: Which option is different from the original image, aside from its orientation?
    '''
    
    input_root = "./stimuli"
    output_root = "./stimuli_vqa"
    task_cnt = 1
    qa_out = []

    same_group = [["N_1", "N_2", "N_3", "RX_0"],["N_1", "N_2", "N_3", "RX_1"],["N_1", "N_2", "N_3", "RX_2"],["N_1", "N_2", "N_3", "RX_3"],["N_1", "N_2", "N_3", "RY_0"],["N_1", "N_2", "N_3", "RY_1"],["N_1", "N_2", "N_3", "RY_2"],["N_1", "N_2", "N_3", "RY_3"],["N_1", "N_2", "N_3", "RZ_0"],["N_1", "N_2", "N_3", "RZ_1"],["N_1", "N_2", "N_3", "RZ_2"],["N_1", "N_2", "N_3", "RZ_3"]]

    for num in range(48):
        random.seed(num+2000)
        mr_dir = f"{input_root}/MR{num+1}"
        for sg in range(len(same_group)):
            out = {}
            out["id"] = f"TSK_SR_2_{task_cnt:04d}"
            out["instruction"] = "Which option is different from the original image, aside from its orientation?"
            shuffled = random.sample(same_group[sg], len(same_group[sg])) 
            out["metadata"] = f'MR{num+1}_'+''.join([item.replace("_", "") for item in shuffled])
            out["original"] = "N_0.png"
            out["answer"] = chr(65+shuffled.index(same_group[sg][3]))
            pre_concat_images = [f"{mr_dir}/{item}.png" for item in shuffled]
            out["options_image"] = concat_image(output_root, out["id"], f"{mr_dir}/N_0.png", pre_concat_images)
            out["options"] = [f"{item}.png" for item in shuffled]
            qa_out.append(out)
            task_cnt += 1

    with open(f"{output_root}/SpaRea_VQAs_2.json", 'w') as f1:
        json.dump(qa_out, f1, indent=4)


def generate_mental_rotation_task_3():
    '''
    codes for generating VQA data for Spatial Reasoning task (question type 3)
    question: Can the right image be obtained by rotating the original image? True or False?
    '''

    input_root = "./stimuli"
    output_root = "./stimuli_vqa"
    task_cnt = 1
    qa_out = []

    same_group = ["N_1", "N_2", "N_3"]
    diff_group = ["RX_1", "RY_2", "RZ_3"]
    for num in range(48):
        random.seed(num+3000)
        mr_dir = f"{input_root}/MR{num+1}"
        for sg in range(len(same_group)):
            out = {}
            out["id"] = f"TSK_SR_3_{task_cnt:04d}"
            out["instruction"] = "Can the right image be obtained by rotating the original image? True or False?"
            shuffled = same_group[sg]
            out["metadata"] = f'MR{num+1}_'+''.join([item.replace("_", "") for item in shuffled])
            out["original"] = "N_0.png"
            out["answer"] = "Ture"
            pre_concat_image = f"{mr_dir}/{shuffled}.png"
            out["options_image"] = concat_single_image(output_root, out["id"], f"{mr_dir}/N_0.png", pre_concat_image)
            out["options"] = f"{shuffled}.png"
            qa_out.append(out)
            task_cnt += 1

        for sg in range(len(diff_group)):
            out = {}
            out["id"] = f"TSK_SR_3_{task_cnt:04d}"
            out["instruction"] = "Can the right image be obtained by rotating the original image? True or False?"
            shuffled = diff_group[sg]
            out["metadata"] = f'MR{num+1}_'+''.join([item.replace("_", "") for item in shuffled])
            out["original"] = "N_0.png"
            out["answer"] = "False"
            pre_concat_image = f"{mr_dir}/{shuffled}.png"
            out["options_image"] = concat_single_image(output_root, out["id"], f"{mr_dir}/N_0.png", pre_concat_image)
            out["options"] = f"{shuffled}.png"
            qa_out.append(out)
            task_cnt += 1

    with open(f"{output_root}/SpaRea_VQAs_3.json", 'w') as f1:
        json.dump(qa_out, f1, indent=4)




#############################################################
# Main functions for reference
#############################################################


def curate_architecture_datasets():
    '''
    Generate instructions for all three types of tasks.
    You should modify the i/o paths in these functions.
    '''

    with open('/examples/architectures_input.json', 'r') as f1:
        original_input = json.load(f1)
    for k1, v1 in original_input.items():
        print(k1)
        address_architectures_data(arch_name=k1)
    generate_instructions_cr()
    generate_instructions_su()
    generate_instructions_sp()


def curate_spatial_reasoning_datasets():
    '''
    Generate VQA data for all three types of questions of Spatial Reasoning task.
    You should modify the i/o paths in these functions.
    '''

    with open('/examples/mental_rotation_input.json', 'r') as f1:
        original_input = json.load(f1)
    for k1, v1 in original_input.items():
        print(k1)
        address_mental_rotation_data(arch_name=k1, original_input=original_input)
    generate_mental_rotation_task_1()
    generate_mental_rotation_task_2()
    generate_mental_rotation_task_3()




if __name__ == "__main__":
    address_architectures_data()


